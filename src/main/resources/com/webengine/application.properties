# This documents contains the preferences and settings for this WebEngine installation.
# Please be careful when changing properties!
# Normally, the GUI of the peer can be reached by: http://127.0.0.1:8080/peer/search.html while
# '127.0.0.1' should be replaced with the IP address of your particular WebEngine installation.


# IMPORTANT: port of the peer, e.g. 8080
# This property must be set and should be identical to the port set in <TOMCAT_HOME>/conf/server.xml in the line similar to:
# <Connector connectionTimeout="20000" port="8080" protocol="HTTP/1.1" redirectPort="8443"/>
config.peer.port=8080

# IMPORTANT: this is the host used for URI construction while crawling and for the connection from and to other peers, 
# e.g. your router's outbound Internet address or your external Amazon AWS IP address in case you use EC2 service 
# (if empty, the locally preferred IP address to connect to the Internet will be used instead)
config.crawler.localHost = 

# IMPORTANT: generate co-occurrence graph databases: 0 means no, 1 means yes
config.crawler.graphdb = 1

# IMPORTANT: peer name (e.g. a preferably, meaningful short name of your affiliation such as your company, university or department); 
# if present, it will be shown at each search result
peer.name=WebEngine

# determines, whether the peer should connect to other peers (1) or not (local mode 0)
peer.networkmode=1

# directory for the local lucene index
# if a simple name without path is given, the folder will normally be placed in: <TOMCAT_HOME>/bin/
config.search.indexDir=index

# lucene version used
config.lucene.version=5.2.1

# This property can be used to add a regex to determine what webcontent is local
# in case empty IP's will be used
config.crawler.uri=

# manually specified Root URI where the crawling starts from (if empty, the peer will construct 
# seeds using config.crawler.localHost, config.crawler.localPath and the local TOMCAT directory automatically)
config.crawler.seeds=

# determines the crawling depth starting from the seeds; 0 means that only the seeds will be crawled
config.crawler.maxdepth=0

# directory for the crawler
# if a simple name without path is given, the folder will normally be placed in: <TOMCAT_HOME>/bin/
config.crawler.StorageFolder=crawler

# this is the port used for URI construction while crawling 
# (if empty, config.peer.port will be used instead)
config.crawler.localPort = 

# this is the path used for URI construction, e.g. documents, when the location of the local html files to be crawled is <TOMCAT_HOME>/webapps/documents
# in case the crawler is configured to build its seeds from a set of html files
config.crawler.localPath = documents

# number of crawlers for crawling the local web content
config.crawler.numberofCrawlers=3

# maximum size in MB for a file to be crawled
config.crawler.maxfilesize=15

# Base name or path of the graph database folders (e.g. German and English co-occurrences)
# if a simple name without path is given, the folders for each supported language will normally be placed in: <TOMCAT_HOME>/bin/
config.graphdb.folder=graphdatabase



# path fragment of the WebEngine service (part of URL to connect to other WebEngine peers)
# This property should not be changed!
config.peer.appPath=/peer

# maximum number of neighbouring peers
peer.maxneighbours=10

# TTL for search messages
ttl=4

# this property sets the top limit of the number of neighbours a search message is forwared to
numberofForwards=3

# these properties set the maximum number of search results displayed
searchresults.centroid=30
searchresults.fulltext=30

# when does the peer crawl the local web content and check for current neighbours as well as new candidate neighbours?
cron.crawler=0/30 * * * * ?
cron.checkCandidates=0/20 * * * * ?

# the following properties refer to text files that contain IP addresses and port numbers of
# fixed neighbouring peers, fixed blacklisted peers and fixed candidate peers
neighbours.filename=
blackList.filename=
candidates.filename=



